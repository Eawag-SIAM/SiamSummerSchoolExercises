## Solution {.tabset}

### R

#### Reading and plotting the data

```{r}
data.survival <- read.table("../../data/model_survival.csv", header=TRUE)
barplot(data.survival$deaths, names=data.survival$time,
        xlab="Time interval", ylab="No. of deaths",
        main="Survival data")
```


#### Defining the likelihood, prior, and posterior


```{r}
loglikelihood.survival <- function(y, N, t, par){

    ## Calculate survival probabilities at measurement points
    ## and add zero "at time-point infinity":
    S <- exp(-par*c(0,t))
    S <- c(S,0)

    ## Calcute probabilities to die within observation windows:
    p <- -diff(S)

    ## Add number of survivors at the end of the experiment:
    y <- c(y, N-sum(y))

    ## Calculate log-likelihood of multinomial distribution at point y:
    LL <- dmultinom(y, prob=p, log=TRUE)

    return(LL)
}
```
Using a log normal distribution as prior
```{r}
logprior.survival <- function(par){

  # a mean and standard deviation that approximate the prior information given above are:
  mu <- 0.6    # since the distribution is skewed, choose it higher than 0.3 (the mode)
  sigma <- 0.7 # a value similar to mu will do

  # calculate the mean and standard deviation in the log-space
  meanlog <- log(mu) - 1/2*log(1+(sigma/mu)^2) #
  sdlog <- sqrt(log(1+(sigma/mu)^2))           #

  # Use these to parameterize the prior
  dlnorm(par, meanlog=meanlog, sdlog=sdlog, log=TRUE)
}

```

We also define a function for the log posterior
```{r}
logposterior.survival <- function(par, data) {
    loglikelihood.survival(data$deaths, N=30, data$time, par) + logprior.survival(par)
}
```

#### Code your own Markov Chain Metropolis sampler

```{r}

# Set sample size (make it feasible)
sampsize <- 5000

# Create an empty matrixto hold the chain:
chain <- matrix(nrow=sampsize, ncol=2)
colnames(chain) <- c("lambda","logposterior")

# Set start value for your parameter:
par.start <- c("lambda"=0.5)

# Compute posterior value of first chain by using your start value
# of the parameter, and the logprior and loglikelihood already defined
chain[1,] <- c(par.start,
               logposterior.survival(par.start, data.survival))

# Run the MCMC:
for (i in 2:sampsize){

  # Propose new parameter value based on previous one (think of propsal distribution):
  par.prop <- chain[i-1,1] + rnorm(1, mean=0, sd=0.01)

  # Calculate logposterior of the proposed parameter value (use likelihood and prior):
  logpost.prop <- logposterior.survival(par.prop, data.survival)

  # Calculate acceptance probability:
  acc.prob <- min( 1, exp(logpost.prop - chain[i-1,2]))

  # Store in chain[i,] the new parameter value if accepted, or re-use the old one if rejected:
  if (runif(1) < acc.prob){
    chain[i,] <- c(par.prop, logpost.prop)
  } else {  # if not accepted, stay at the current parameter value
    chain[i,] <-  chain[i-1,]
  }
}

```

Plot the resulting chain. Does it look reasonable? Have you selected an appropriate jump distribution?

```{r}
plot(chain[,"lambda"], ylab=expression(lambda), pch=19, cex=0.25, col='black')

```

Find the value of $\lambda$ within your sample, for which the posterior is maximal.

```{r}
# Find the parameter value corresponding to the maximum posterior density
chain[which.max(chain[,2]),]
```

Create a density plot of the posterior sample using `plot(density())`,
but remove the burn-in first. Inspect the chain in the figure above: how
many samples would you discard as burn-in?

```{r}
# Create a density plot of the posterior sample using `plot(density())` without burn-in
plot(density(chain[1000:nrow(chain),1]), xlab=expression(lambda), main="")
```



### Julia


#### Reading and plotting the data

```{julia, out.width = '80%'}
using DataFrames
import CSV
using Plots

survival_data = CSV.read("../../data/model_survival.csv",
                         DataFrame)

bar(survival_data.deaths,
    labels = false,
    xlabel = "Times interval",
    ylabel = "No. of deaths",
    title = "Survival Model")
```

#### Defining the likelihood, prior, and posterior

```{julia}
using Distributions

function loglikelihood_survival(N::Int, t::Vector, y::Vector, λ)
    S = exp.(-λ .* t)
    S = [1; S; 0]
    p = -diff(S)
    ## Add number of survivors at the end of the experiment:
    y = [y; N-sum(y)]

    logpdf(Multinomial(N, p), y)
end

function logprior_survival(λ)
    # a mean and standard deviation that approximate the prior information given above:
    m = 0.5     # since the distribution is skewed, choose it higher than 0.3 (the mode)
    sd = 0.5    # a value similar to the mean will do

    # calculate the mean and standard deviation in the log-space
    μ = log(m/sqrt(1+sd^2/m^2))
    σ = sqrt(log(1+sd^2/m^2))

    # Use these to parameterize the prior
    return logpdf(LogNormal(μ, σ), λ)
end
```

Note, we check if a parameter value is possible before calling the
likelihood function:
```{julia}
function logposterior_survival(λ, data)
    lp = logprior_survival(λ)
    if !isinf(lp)
        lp += loglikelihood_survival(30, data.time, data.deaths, λ)
    end
    lp
end
```

#### Code your own Markov Chain Metropolis sampler


```{julia, results="hide"}
# set your sampsize
sampsize = 5000

# create empty vectors to hold the chain and the log posteriors values
chain = Vector{Float64}(undef, sampsize);
log_posts = Vector{Float64}(undef, sampsize);

# Set start value for your parameter
par_start = 0.5

# compute logposterior value of of your start parameter
chain[1] = par_start
log_posts[1] = logposterior_survival(par_start, survival_data)

# Run the MCMC:
for i in 2:sampsize
    # Propose new parameter value based on previous one (choose a propsal distribution):
    par_prop = chain[i-1] + rand(Normal(0, 0.01))

    # Calculate logposterior of the proposed parameter value:
    logpost_prop = logposterior_survival(par_prop, survival_data)

    # Calculate acceptance probability by using the Metropolis criterion min(1, ... ):
    acc_prob = min(1, exp(logpost_prop - log_posts[i-1]))

    # Store in chain[i] the new parameter value if accepted, or re-store old one if rejected:
    if rand() < acc_prob # rand() is the same as rand(Uniform(0,1))
        chain[i] = par_prop
        log_posts[i] = logpost_prop
    else # if not accepted, stay at the current parameter value
        chain[i] = chain[i-1]
        log_posts[i] = log_posts[i-1]
    end
end
```

The so called trace-plot can give us an idea how well the chain has converged:
```{julia, out.width = '80%'}
plot(chain, label=false, xlab="iteration", ylab="λ")
```

Find the parameter value corresponding to the maximum posterior density
```{julia}
chain[argmax(log_posts)]
log_posts[argmax(log_posts)]
```

A histogram of the posterior. Note, we removed the first 1000
iterations as burn-in:
```{julia, out.width = '80%'}
histogram(chain[1000:end], xlab="λ", label=false)
```
