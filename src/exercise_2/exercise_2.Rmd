---
title: 'Exercise 2: Bayesian inference with elementary Markov Chain sampling'
author: "Eawag Summer School in Environmental Systems Analysis"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    number_sections: no
    toc: TRUE
    toc_depth: 2
params:
  showsolutions: TRUE
---

**Objectives**

* Implement the Metropolis algorithm for a one-parameter model, and
  apply it to generate a posterior parameter sample, for the model
  "survival".
* Calculate a Markov chain sample of the posterior model parameter
  distribution. Starting from a first guess jump distribution, construct a
  simple algorithm to improve the jump distribution for higher
  efficiency.
* Use graphical analysis and convergence tests to asses the quality of
  the Markov chain samples.



# 1. Implement an elementary Markov Chain sampler (recommended)


In this exercise, you will write your own code to implement the most
elementary MCMC sampler, the Metropolis algorithm for one dimension.
Recall that samplers
can be used to sample from any distribution, and that they are not
linked to Bayesian concepts per se. In Bayesian inference, however, they
are especially useful to sample from the posterior distribution. You
will apply your self-coded sampler to sample from the posterior
distribution of the one-parameter model "survival", given the observed
data in the file `model_survival.csv`.

## Before you get started

We want to use the model "Survial" from yesterdays exercise and the
date `model_survival.csv` to test our sampler. The
experiment was started done with `N=30` individuals (this information
is not contained in the data set).

### Reading and plotting the data {.tabset}

It's always a good idea to look at the data first.

#### R
```{r}
data.survival <- read.table("../../data/model_survival.csv", header=TRUE)
barplot(data.survival$deaths, names=data.survival$time,
        xlab="Time interval", ylab="No. of deaths",
        main="Survival data")
```

#### Julia
```{julia}
survival_data = CSV.read(joinpath("..", "..", "data", "model_survival.csv"),
DataFrame);

deaths = survival_data[:, "deaths"];
bar(deaths,
    labels = false,
    xlabel = "Times interval",
    ylabel = "No of deaths",
    title = "Survival Model")
```

### Defining the likelihood, prior, and posterior

In the next step we will need the posterior density (or more accurately: something that is
proportional to the posterior density) for the model "survival". Remember that,
$$
p(\lambda|y)\propto p(\lambda,y)=p(y|\lambda)p(\lambda)
$$
This means that we first need the likelihood function $p(y|\lambda)$
and the prior $p(\lambda)$.

#### Likelihood {.tabset}

##### R
The likelihood is given below (copied from Exercise 1):
```{r}
loglikelihood.survival <- function(y, N, t, par){

    ## return -Inf, if par is negative:
    if(any(par<0)) return(-Inf)

    ## Calculate survival probabilities at measurement points
    ## and add zero "at time-point infinity":
    S <- exp(-par*c(0,t))
    S <- c(S,0)

    ## Calcute probabilities to die within observation windows:
    p <- -diff(S)

    ## Add number of survivors at the end of the experiment:
    y <- c(y, N-sum(y))

    ## Calculate log-likelihood of multinomial distribution at point y:
    LL <- dmultinom(y, prob=p, log=TRUE)

    return(LL)
}
```

##### Julia
The likelihood can be implemented like this, copied from Exercise 1.
```{julia, results = 'hide'}
function loglikelihood_linear(beta, gamma, sigma, x, y)
    y_det = beta .* x .+ gamma
    return sum(logpdf.(Normal.(y_det, sigma), y))
end
```

Note, that we return `-Inf` if a negative parameter is given.
However, we still need a prior distribution for the model parameter $\lambda$ that
encodes that it must be positive.


### Prior {.tabset}
The parameter $\lambda$  must be positive. Furthermore, we know
that values around 0.3 are quite plausible, and that values below 0.1 and above 0.7 are pretty unlikely.
Which distribution would you choose for the prior?

Implement a function that returns the logarithm of the probability density of the prior distribution
for $\lambda$.

#### R
You can use a `lognormal` prior distribution by understanding and filling-in the block below.
```{r eval=FALSE}

# we use a lognormal distribution, which naturally accounts
# for the fact that lambda is positive

logprior.survival <- function(par){

  # a mean and standard deviation that approximate the prior information given above are:
  mu <- ???    # since the distribution is skewed, choose it higher than 0.3 (the mode)
  sigma <- ??? # a value similar to mu will do

  # calculate the mean and standard deviation in the log-space
  meanlog <- log(mu) - 1/2*log(1+(sigma/mu)^2) # R assumes that the mean is specified for the associated normal variable
  sdlog <- sqrt(log(1+(sigma/mu)^2))           # R assumes that the st.dev. is specified for the associated normal variable

  # Use these to parameterize the prior
  dlnorm(???) # last line is returned by default by r-function, use ?dlnorm to get help in the console
}
```
#### Julia
You can use a `lognormal` prior distribution by understanding and filling-in the block below.
```{julia, eval = FALSE}
function logprior_survival(λ)
    # a mean and standard deviation that approximate the prior information given above are:
    μ = ??? # since the distribution is skewed, choose it higher than 0.3 (the mode)
    σ = ??? # a value similar to mu will do

    # calculate the mean and standard deviation in the log-space
    meanlog = log(μ) - 1/2*log(1+(σ/μ)^2)
    sdlog = sqrt(log(1+(σ/μ)^2))

    # Use these to parameterize the prior
    return logpdf(Normal(???), ???)
end

```

### Posterior {.tabset}

Finally,  define a function that evaluates the density of
the log posterior distribution.

This function should take the data `model_survival.dat` and a
parameter value as inputs.

#### R
```{r, eval=FALSE}
log.posterior <- function(par, data) {
    ...
}
```

#### Julia
```{julia, eval = FALSE}
function log_posterior(λ, data)
    return ???
end
```

## Code your own Markov Chain Metropolis sampler {.tabset #mcmc}

Implement your own elementary Markov Chain Metropolis sampler and run
it with the posterior defined above for a few thousand iterations. You
can find a description of the steps needed in Carlo's slides.

### R

```{r eval=FALSE}

#manually set sample size (make it feasible)
sampsize <- 5000

# Create an empty chain:
survival.chain <- matrix( nrow=sampsize, ncol=2 )
colnames(survival.chain) <- c("lambda","logposterior")

# Set start value for your parameter:
par.start <- ???

# compute posterior value of first chain by using your start value of the parameter, and the logprior and loglikelihood already defined
survival.chain[1,] <- ???

# Run the MCMC:
for (i in 2:sampsize){ # complete the loop below

  # Propose new parameter value based on previous one (think of propsal distribution):
  par.prop <- ???

  # Calculate logposterior of the proposed parameter value (use likelihood and prior):
  logpost.prop <- ???

  # Calculate acceptance probability by using Metropolis criterion min(1, ... ):
  acc.prob <- ???

  # Store in survival.chain[i,] the new parameter value if accepted, or re-store old one if rejected:
  if (runif(1) < acc.prob){
    ???
   } else {
    ????
   }
}

```

### Julia
```{julia, eval = FALSE}
#manually set your sampsize
sampsize = 5000

#create an undef chain
survival_chain = Array{Float64}(undef, sampsize, 2)


# Set start value for your parameter:
par_start = ???


# compute posterior value of first chain by using your start value of the parameter, 
# and the logprior and loglikelihood already defined
survival_chain[1,:] = ???

# Run the MCMC:
for i in 2:sampsize

  # Propose new parameter value based on previous one (think of proposal distribution):
  par_prop = ???

  # Calculate logposterior of the proposed parameter value (use likelihood and prior):
  logpost_prop = ???

  # Calculate acceptance probability:
  acc_prob = ???

  # Store in survival_chain[i,] the new parameter value if accepted, or re-store old one if rejected:
  if rand(Uniform(0,1)) < acc_prob
    ???
  else # if not accepted, stay at the current parameter value
    ???
  end
end
```


Experiment with you sampler:
- Plot the resulting chain. Does it look reasonable?
- Test the effect  of different jump distribution.
- Find the value of $\lambda$ within your sample, for which the posterior is maximal.
- Create a histogram or density plot of the posterior sample. Look at
the chain plots to decide how many the burn-in sample you need to remove.




# 2. Sample from the posterior for the monod model (recommended) {#task2}

The main difference of the "Monod" compared to the "Survival" model is
that it has more than on parameter that we would like to infer.

You can either generalize our own metropolis sampler to higher
dimension or use a sampler from a package.



## Read data

We use the data `model_monod_stoch.csv`:

```{r result="hide"}
data.monod <- read.table("../../data/model_monod_stoch.csv", header=T)
plot(data.monod$C, data.monod$r, xlab="C", ylab="r", main='"model_monod_stoch.csv"')
```



## Define  likelihood, prior, and posterior {.tabset}

Again, we need to prepare a function that evaluates the for the log
posterior. You can use the templates below.

### R

```{r eval=FALSE}
# Logprior for model "monod": lognormal distribution

prior.monod.mean <- 0.5*c(r_max=5, K=3, sigma=0.5)
prior.monod.sd   <- 0.5*prior.monod.mean

logprior.monod <- function(par,mean,sd){

    sdlog    <- ???
    meanlog  <- ???

    return(sum(???)) # we work log-space, hence sum over multiple independent data points
}

# Log-likelihood for model "monod"

loglikelihood.monod <- function( y, C, par){

  # deterministic part:
  y.det <- ???

  # Calculate loglikelihood:
  return( sum(???) )
}

# Log-posterior for model "monod" given data 'data.monod' with layout 'L.monod.obs'

logposterior.monod <- function(par) {
  logpri <- logprior.monod(???)
  if(logpri==-Inf){
    return(-Inf)
  } else {
    return(???) # sum log-prior and log-likelihood
  }
}

```

### Julia
```{julia, eval = FALSE}
#set parameters
r_max, K, sigma = 5, 3, 0.5
par = [r_max, K, sigma]

prior_monod_mean = 0.5 .* par
prior_monod_sd = 0.25 .*par

# Logprior for model "monod": lognormal distribution
function logprior_monod(par, mean, sd)
    sdlog = ???
    meanlog = ???
    return sum(???) #sum because we are in the log-space
end


# Log-likelihood for model "monod"
function loglikelihood_monod(r_max, K, sigma, C::Vector, Y::Vector)
    y_det = ???
    return sum(???)
end

# Log-posterior for model "monod"
function logposterior_monod(par)
    logpri = logprior_monod(???)
    if logpri == -Inf
        return ???
    else
        r_max, K, sigma = par
        return ???    # sum log-prior and log-likelihood
    end
end 
```


## Create initial chain {.tabset}

To create the initial chain, let us first define some of the necessary
prerequisites. For the jump distribution, assume a diagonal covariance
matrix with reasonable values. Recall that diagonal covariance matrices
(with zero-valued off-diagonal entries) correspond to independent
proposals.

### R
The code below used the function `adaptMCMC::MCMC`. If the adaptation
is set to `FALSE` this corresponds to the basic metropolis sampler. Of
course, feel free to use you own implementation instead!

```{r eval=FALSE}

library(adaptMCMC)


## As start values for the Markov chain we can use the mean of the prior
par.start <- c(r_max=2.5, K=1.5, sigma=0.25)


## sample
monod.chain <- adaptMCMC::MCMC(p  = ???,
                               n = ???,
                               init = ???,
                               adapt = FALSE # for this exercise we do not wat to use automatic adaptation
                               )
monod.chain.coda <- adaptMCMC::convert.to.coda(monod.chain) # this is useful for plotting

```

Plot the chain and look at the rejection rate of this chain to gain
information if the standard deviation of the jump distribution should
be increased (if rejection frequency is too low) or decreased (if it
was too high). What do you think?

```{r eval=FALSE}
monod.chain$acceptance.rate

plot(monod.chain.coda)

pairs(modod.chain$samples)
```

### Julia
Example of manual implementation.
```{julia, eval = FALSE}
#manually set parameters
sampsize = 5000
par_start = prior_monod_mean
prop_sd = 0.1 .* par_start
prop_cor = LinearAlgebra.I


#create an undef chain
monod_chain = Array{Vector}(undef, sampsize, 2)
monod_chain[1, :] = ???


#run MCMC
for i in 2:sampsize


    # Propose new parameter value based on previous one (think of proposal distribution):
    par_prop = ???

    
    # Calculate logposterior of the proposed parameter value:
    logpost_prop = ???

    # Calculate acceptance probability:
    acc_prob = ???

    # Store in monod_chain[i,] the new parameter value if accepted, or re-store old one if rejected:
    if rand(Uniform(0,1)) < acc_prob
        ???
    else # if not accepted, stay at the current parameter value
        ???
    end
end
```

## Improve jump distribution  {.tabset}

The plot of the previous chain give us some indication how a more
efficient jump distribution could look like.

- Try to manualy change the varianc eof the jump distribution. Can we
  get better chains?

- Use the previous chain and estiamte it's covariance. Does a
  correlated jump work better?

### R
The function `adaptMCMC::MCMC` takes argument `scale` to modify the
jump distribution:
```
scale: vector with the variances _or_ covariance matrix of the jump
          distribution.
```

### Julia
TODO


## Residual Diagnostics {.tabset}

The assumptions about the observation noise should be validated. Often
we can do this by looking at the model residuals, that is the
difference between observations and model prediction.

- Find the parameters in the posterior sample that correspond to the
largest posterior value (the so called maximum posterior estimate, MAP).

- Run the deterministic "Monod" model with this parameters and
analyze the residuals.
   * Are they normal distributed?
   * Are they independent
   * Are they centered around zero?
   * Do you see any suspicious structure?

### R
Use the function `qqnorm` and `acf` can be helpful.

### Julia
TODO



# 3. Sample from the posterior for the growth model

The goal is to sample for the posterior distribution of the "Growth"
model. This task is very similar to the previous one except that we
provide less guidance.

1. Read data `model_growth.csv`
2. Define likelihood, prior, and posterior. What assumptions do you make?
3. Run MCMC sampler
4. Check convergence and mixing. If needed, modify the jump
   distribution
5. Perform residual diagnostics. Are the assumption of the likelihood
   function ok?
