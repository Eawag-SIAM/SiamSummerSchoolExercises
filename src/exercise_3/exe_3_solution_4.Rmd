## Solution {.tabset}

- The expression $p(Y^* | x^*, \theta)$ is  our probabilistic
model, so the distribution of $Y^*$ given some inputs and parameters
(i.e. the likelihood function).

- Typically we do not have the posterior distribution $p(\theta | y,
x)$ in analytical form but a sample from it. Hence we cannot compute
the integral over all $\theta$ (besides that this would be difficult
anyway). Instead, we use an approach to obtain samples from $Y^*$:

  1. Take a sample $\theta'$ from $p(\theta | y, x)$.
  2. Take a sample from $p(Y^* | x^*, \theta')$.

  Both steps are computationally cheap. For 1) we already have samples
from the parameter inference, and 2) is simply a forward simulation
of the model as we did in exercises 1. Hence, producing posterior
predictions is much cheaper than inference.

  (Technically we sample from the joint distribution $p(Y^*, \theta|
  x^*, y, x)$). The  marginalization over $\theta$ is done by
  simply ignoring the sampled $\theta$s and looking only at $Y^*$.)

- It is important to keep in mind that the resulting prediction
  intervals are only correct as long the underlying model is correct! For
  example, it seems rather risky to extrapolate with the monod model
  to large concentrations outside of the calibration data range.

### R

We take the function for forward simulations from exercises 1:
```{r}
simulate.monod.stoch <- function(par, C){
    ## run model
    r.det <- model.monod(par, C)

    ## generate noise
    z <- rnorm(length(C), 0, par["sigma"])

    return(r.det + z)
}
```

```{r}
m <- 1000 # number of samples

Cstar <- c(10, 12, 14, 16)               # new inputs

## posterior samples, removing burn-in
post.samples <- RAM$samples[1000:10000,]

Ystar <- matrix(NA, ncol=length(Cstar), nrow=m)
colnames(Ystar) <- paste0("C_", Cstar)
for(k in 1:m){
    ## 1) take a sample from posterior
    i <- sample(ncol(post.samples), 1)
    theta <- post.samples[i,]

    ## 2) forward simulation from model
    Ystar[k,] <- simulate.monod.stoch(theta, Cstar)
}
```

We can also plots the predictions with uncertainty bands:
```{r}
Ystar.quants <- apply(Ystar, MARGIN=2, FUN=quantile, probs=c(0.05, 0.5, 0.95))

## plot result
plot(Cstar, Ystar.quants[2,], ylab="r", ylim=c(0, 5))
polygon(c(Cstar,rev(Cstar)), c(Ystar.quants[1,],rev(Ystar.quants[3,])), col = "grey85")
lines(Cstar, Ystar.quants[2,], col=2, lwd=2, type="b")
```

### Julia

We take the function for forward simulations from exercises 1:
```{julia}
# function to simulate stochastic realisations
function simulate_monod_stoch(C, par)
    Ydet = model_monod(C, par)
    z = rand(Normal(0, par.sigma), length(Ydet)) # adding noise
    Ydet .+ z
end
```

```{julia}
m = 1000
Cstar = [10,12,14,16]
Ystar = Matrix{Float64}(undef, m, length(Cstar));
θ = copy(θinit);
for k in 1:m
    i = rand(1000:10000)
    θ .= res.X[:,i]
    Ystar[k,:] = simulate_monod_stoch(Cstar, θ)
end
```

```{julia, out.width = '80%'}
# compute quantile
low_quantile = [quantile(Ystar[:,i], 0.05) for i in 1:length(Cstar)];
med_quantile = [quantile(Ystar[:,i], 0.5) for i in 1:length(Cstar)];
upper_quantile = [quantile(Ystar[:,i], 0.95) for i in 1:length(Cstar)];
plot(Cstar, upper_quantile,
     fillrange = low_quantile,
     labels = false,
     xlabel = "C",
     ylabel = "r",
     ylim=(0,5));
plot!(Cstar, med_quantile, marker=:circle,
      labels = false)
```

### Python

We take the function for forward simulations from exercises 1:
```{python}
def simulate_monod_stoch(par, C):
    """
    Simulate the Monod model with stochastic noise.
    
    Arguments:
    ----------
    - par: Array containing the following parameters:
        - r_max: maximum growth rate
        - K: half-saturation concentration
        - sigma: standard deviation of noise
    - C: numpy array containing substrate concentrations
    
    Value:
    ------
    A numpy array representing the growth rate with stochastic noise added.
    """
    # Run deterministic model
    r_det = model_monod(par, C)

    # Generate noise using a normal distribution with mean 0 and standard deviation `sigma`
    sigma = par[-1]
    z = np.random.normal(0, sigma, size=len(C))
    
    # Add noise to the deterministic model results
    return r_det + z
```
We can also select the samples from the previous exercise to work with:

```{python}
# Here we select the mean of the walkers defined in the previous exercise as a single sampler chain
reshaped_chain = np.mean(chain_samples, axis=1)

# Convert reshaped chain samples to pandas DataFrame
chain_df = pd.DataFrame(reshaped_chain, columns=['r_max', 'K', 'sigma'])
```

```{python}
m = 1000  # number of samples
Cstar = np.array([10, 12, 14, 16])  # new inputs

# Extract posterior samples, removing burn-in
post_samples = chain_df.iloc[1000:].values  # Adjust the slicing as needed based on your data

# Initialize the Ystar matrix
Ystar = np.empty((m, len(Cstar)))
columns = [f"C_{c}" for c in Cstar]

# Perform the sampling and forward simulation
for k in range(m):
    # 1) Take a sample from posterior
    i = np.random.randint(post_samples.shape[0])
    theta = post_samples[i, :]

    # 2) Forward simulation from model
    Ystar[k, :] = simulate_monod_stoch(theta, Cstar)

# Convert Ystar to a DataFrame for better readability (optional)
Ystar_df = pd.DataFrame(Ystar, columns=columns)
print(Ystar_df)
```

We can also plots the predictions with uncertainty bands:
```{python}
# Compute quantiles
Ystar_quants = np.quantile(Ystar, q=[0.05, 0.5, 0.95], axis=0)

# Plot the result
plt.figure(figsize=(10, 6))
plt.plot(Cstar, Ystar_quants[1,], 'o-', color='red', label='Median', linewidth=2)
plt.fill_between(Cstar, Ystar_quants[0,], Ystar_quants[2,], color='grey', alpha=0.5, label='5th-95th Percentile')
plt.xlabel('Cstar')
plt.ylabel('r')
plt.ylim(0, 5)
plt.title('Quantile Plot')
plt.legend()
plt.show()
```